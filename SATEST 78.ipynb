{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Len: 320\n",
      "Hop Len: 160\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa as lr\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/HouseW/LocalPython/SATEST-main/SATEST-main/utils.py\")\n",
    "from utils import FrameExtractor, LPC, ref_derbin, derbin, auto_corr\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "# plt.rc('font', size=20)\n",
    "# plt.rc('axes', labelsize=25)\n",
    "# plt.rc('xtick', labelsize=25)\n",
    "# plt.rc('ytick',labelsize=25)\n",
    "# plt.rc('legend', fontsize=20)\n",
    "# plt.rc('figure', titlesize=50)\n",
    "# plt.rc('figure', autolayout=True)\n",
    "\n",
    "sr = 16000\n",
    "win_time = 0.02\n",
    "dftlen = 512\n",
    "# Window Sample의 길이 표현\n",
    "win_len = int(win_time * sr)\n",
    "hop_len = int(win_len * 0.5)\n",
    "print(\"Window Len:\",win_len)\n",
    "print(\"Hop Len:\",hop_len)\n",
    "\n",
    "file_path = 'sa0_new.wav'\n",
    "yr,ori_sr = lr.load(file_path,sr=sr)\n",
    "time = np.linspace(0,len(yr),len(yr),endpoint=False)/sr\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing and Overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Overlap Test\n",
    "\n",
    "# h = lr.filters.get_window(window=\"hann\", Nx=50)\n",
    "# z = np.zeros_like(h)\n",
    "# h = np.concatenate([h,z])\n",
    "# h2 = np.roll(h,25)\n",
    "# plt.plot(h)\n",
    "# plt.plot(h2)\n",
    "# plt.show()\n",
    "\n",
    "# # h3 = h+h2+np.roll(h2,25)\n",
    "# h3 = h+h2\n",
    "# # print(h3)\n",
    "# plt.plot(h3)\n",
    "# plt.show()\n",
    "\n",
    "# ### OLA를 하려면 hamming은 1.08배 scale이 되어야 하는구나!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# ### Read input waves\n",
    "# # file_path = \"yonseicrop.wav\"\n",
    "# file_path = 'sa0_new.wav'\n",
    "\n",
    "# ### Read Audio Files\n",
    "# yr,ori_sr = lr.load(file_path,sr=sr)\n",
    "# # print(f\"Loaded: {file_path}, Shape: {np.array(yr).shape}, Original sr: {ori_sr}\")\n",
    "\n",
    "# # Time axis\n",
    "# time = np.linspace(0,len(yr),len(yr),endpoint=False)/sr\n",
    "# plt.plot(time,yr)\n",
    "# plt.xlim(0,time[-1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Frame Extractor\n",
    "# ### Extract frames by windowing\n",
    "# ## 겹치는 Frame을 overlap 해도 원신호에 영향이 가지 않는다\n",
    "\n",
    "# FE = utils.FrameExtractor(yr,win_len,hop_len)\n",
    "# frame_arr = FE.extract_frames(win_type=\"hann\")\n",
    "\n",
    "# # plt.plot(frame_arr[0])\n",
    "# # plt.plot(frame_arr[1])\n",
    "# # plt.show()\n",
    "\n",
    "# x = np.concatenate([frame_arr[0],np.zeros_like(frame_arr[0])])\n",
    "# y = np.concatenate([frame_arr[1],np.zeros_like(frame_arr[1])])\n",
    "# y = np.roll(y,hop_len)\n",
    "# z = x+y / 1.08\n",
    "\n",
    "# plt.plot(z)\n",
    "# # plt.show()\n",
    "# # plt.plot(yr[:win_len*2],'--')\n",
    "# plt.title(\"Reconstructed and Original\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Visualization In Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 0번 frame 부터 5개를 표시해보자\n",
    "# \"\"\" Frame Visualization Between Total \"\"\"\n",
    "\n",
    "# ind1 = 0\n",
    "# ind2 = 30\n",
    "# fig, axes = plt.subplots(5,1,figsize=(15,20))\n",
    "\n",
    "# time = np.arange(0, len(yr)/sr, 1/sr)\n",
    "# for i in range(5):\n",
    "#     startind1 = FE.hop_len * ind1\n",
    "#     endind1 = FE.hop_len * ind1 + FE.win_len\n",
    "#     startind2 = FE.hop_len * ind2\n",
    "#     endind2 = FE.hop_len * ind2 + FE.win_len\n",
    "#     print(\"startind:\", startind1)\n",
    "#     frame1 = frame_arr[ind1]\n",
    "#     frame2 = frame_arr[ind2]\n",
    "#     ind1 += 1\n",
    "#     ind2 += 1\n",
    "\n",
    "#     # 기존 waveform 그리기\n",
    "#     axes[i].plot(time, yr, label='waveform')\n",
    "    \n",
    "#     # 추출된 frame 그리기\n",
    "#     axes[i].plot(time[startind1: endind1], frame1, label='frame {}'.format(2*i + 1), linestyle='--')\n",
    "#     axes[i].plot(time[startind2: endind2], frame2, label='frame {}'.format(2*i + 2), linestyle='--')\n",
    "    \n",
    "#     # axes[i].set_xlabel('Time(s)', fontsize=18, fontweight='bold')\n",
    "#     axes[i].set_ylabel('Amplitude', fontsize=14, fontweight='bold')\n",
    "#     axes[i].set_title('Frame index: {},{}'.format(ind1, ind2), fontsize=16, fontweight='bold')\n",
    "#     axes[i].tick_params(axis='both', labelsize=20)\n",
    "#     axes[i].set_xlim(0, time[-1])\n",
    "\n",
    "#     # axes[i].legend(fontsize=20,loc='lower left')\n",
    "#     axes[i].grid()\n",
    "    \n",
    "#     # plt.figure(figsize=[15,6])\n",
    "#     # plt.subplot(2,2,1)\n",
    "#     # plt.plot(frame1)\n",
    "#     # plt.grid()\n",
    "#     # plt.xlim(0,len(frame1)-1)\n",
    "#     # plt.title(\"Unvoiced\")\n",
    "#     # plt.xlabel(\"Samples\")\n",
    "#     # plt.subplot(2,2,2)\n",
    "#     # plt.plot(frame2)\n",
    "#     # plt.grid()\n",
    "#     # plt.xlim(0,len(frame2)-1)\n",
    "#     # plt.title(\"voiced\")\n",
    "#     # plt.xlabel(\"Samples\")\n",
    "\n",
    "# # plt.tight_layout()  # subplot 간의 간격 조절\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 각 frame 에서의 autocorrelation 계산 해보기\n",
    "\n",
    "# ## Auto Correlation Sequence with signal length\n",
    "# def auto_corr(signal):\n",
    "#     corr = np.correlate(signal, signal, mode='full')\n",
    "#     corr = corr[len(corr)//2:]\n",
    "#     return corr \n",
    "\n",
    "# # 각 frame 속에서 p차 LPC 계수의 계수를 반환한다\n",
    "# def LPC(frame, order=10):\n",
    "#     coeff_arr = np.zeros(order)\n",
    "#     # error\n",
    "#     if len(frame) < order:\n",
    "#         print('frame is longer than order')\n",
    "#         return -1\n",
    "#     # Tx = b\n",
    "#     ac = auto_corr(frame)[:order]\n",
    "#     mat_T = make_toeplitz(ac)\n",
    "#     vec_b = auto_corr(frame)[1:order+1]\n",
    "#     coeff_arr  = np.dot(np.linalg.inv(mat_T),vec_b)\n",
    "#     return coeff_arr\n",
    "\n",
    "# # Make Toeplitz Matrix using Auto Correlation\n",
    "# def make_toeplitz(ac):\n",
    "#     p = len(ac)\n",
    "#     toeplitz_mat = np.zeros((p,p))\n",
    "#     ac_flip = ac[::-1][:-1]\n",
    "    \n",
    "#     for i in range(p):\n",
    "#         toeplitz_mat[i,:] = np.concatenate((ac_flip[p-i-1:],ac[:p-i]))\n",
    "        \n",
    "\n",
    "#     return toeplitz_mat\n",
    "\n",
    "# # Derbin's Algorithm (As a reference)\n",
    "# def ref_derbin(r, order):\n",
    "    \n",
    "#     # r : 1-D auto corr array\n",
    "#     a = np.zeros((order+1,order+1))\n",
    "    \n",
    "#     # store prediction error for each step\n",
    "#     E = np.zeros(order+1)\n",
    "    \n",
    "#     # First coeff\n",
    "#     a[0][0] = 1\n",
    "    \n",
    "#     # Initial prediction error : power\n",
    "#     E[0] = r[0]\n",
    "    \n",
    "#     # iterate from 1 to order p \n",
    "#     for i in range(1,order+1):\n",
    "#         sum_j = sum(a[i-1][j] * r[i-j] for j in range(1,i))\n",
    "#         k_i = (r[i] - sum_j ) / E[i-1]\n",
    "        \n",
    "#         # Update coefficeints for current step\n",
    "#         a[i][i] = k_i\n",
    "#         for j in range(1,i):\n",
    "#             a[i][j] = a[i-1][j] - k_i * a[i-1][i-j]\n",
    "            \n",
    "#         #Update Error\n",
    "#         E[i] = (1-k_i**2) * E[i-1]\n",
    "#         # print(\"i={}, ki={}\".format(i,k_i))\n",
    "#     # Extract final coeff, exclude a0    \n",
    "#     coeff = a[order][1:]\n",
    "#     return coeff,E\n",
    "\n",
    "# # My Derbin's Algorithm\n",
    "# def derbin(r, p):\n",
    "#     E = np.zeros(p+1)\n",
    "#     a = np.zeros((p+1,p+1))\n",
    "    \n",
    "#     a[0][0] = 1\n",
    "#     E[0] = r[0]\n",
    "\n",
    "#     for i in range(1,p+1):\n",
    "#         ## sigma\n",
    "#         j=1\n",
    "#         sumj = 0\n",
    "#         while(j <= i-1):\n",
    "#             sumj+=a[i-1][j]*r[i-j]\n",
    "#             j += 1\n",
    "        \n",
    "#         k_i = (r[i] - sumj) / E[i-1] \n",
    "#         a[i][i] = k_i\n",
    "\n",
    "#         ## i-order 새로운 coeff 갱신\n",
    "#         for j in range(1,i):\n",
    "#             a[i][j] = a[i-1][j] - k_i * a[i-1][i-j]\n",
    "            \n",
    "#         E[i] = (1 - k_i**2)*E[i-1]\n",
    "#         coeff = a[p][1:]\n",
    "#     return coeff,E\n",
    "\n",
    "\n",
    "\n",
    "# # 예제 자동 상관 함수\n",
    "# auto_corr_sequence = np.array([0, 1, 2, 3,4,5])\n",
    "\n",
    "# # Toeplitz 행렬 생성\n",
    "# # toeplitz_result = make_toeplitz(auto_corr_sequence)\n",
    "# # print(LPC([1,2,34,5,6,7,8],order=6))\n",
    "\n",
    "# # print(len(frame_arr))\n",
    "\n",
    "# ########################## LPC on every frames\n",
    "# # frame_len = len(frame_arr)\n",
    "# # coeff_arr = []\n",
    "# # # print(frame_len, len(coeff_arr))\n",
    "# # for ind,frame in enumerate(frame_arr):\n",
    "# #     # 매 frame에서 LPC 계수 계산\n",
    "# #     coeff = LPC(frame,order=10)\n",
    "# #     coeff_arr.append(coeff) \n",
    "# #     break\n",
    "# y = frame_arr[30]\n",
    "\n",
    "# derbin(auto_corr(y),3)\n",
    "# print(\"\\n\")\n",
    "# derbin(auto_corr(y),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### librosa의 LPC와 비교하는 것\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy\n",
    "# y, sr = lr.load(lr.ex('libri1'), duration=0.020)\n",
    "\n",
    "# y = yr\n",
    "# s = 16000\n",
    "# a = lr.lpc(y, order=5)\n",
    "# b = np.hstack([[0], -1 * a[1:]])\n",
    "# print(a)\n",
    "# print(b)\n",
    "\n",
    "# mya = LPC(y, order=5)\n",
    "# myb = np.hstack([[0],mya[:]])\n",
    "# print(mya)\n",
    "# print(myb)\n",
    "\n",
    "# myy = scipy.signal.lfilter(myb, [1], y)\n",
    "# y_hat = scipy.signal.lfilter(b, [1], y)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(y)\n",
    "# # ax.plot(y_hat, linestyle='--')\n",
    "# ax.plot(myy ,label=\"mine\")\n",
    "# ax.legend(['y', 'y_hat'])\n",
    "# ax.set_title('LP Model Forward Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rectangular\n",
      "From 8200 samples, total 50 frames are generated\n",
      "[ 1.0000000e+00 -1.8354051e+00  9.0559781e-01 -6.7733682e-04]\n",
      "librosa LPC: \t\t [ 1.8354051e+00 -9.0559781e-01  6.7733682e-04]\n",
      "Matrix Inverse: \t [ 1.5108497  -0.37836478 -0.22113916]\n",
      "Derbin's Inverse: \t [ 1.5108497  -0.37836478 -0.22113916]\n",
      "myDerbin's Inverse: \t [ 1.5108497  -0.37836478 -0.22113916]\n"
     ]
    }
   ],
   "source": [
    "### librosa의 LPC와 비교하는 것\n",
    "### LPC 계수가 올바르게 추출 되었는지 디버깅\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from utils import FrameExtractor, LPC, ref_derbin, derbin, auto_corr\n",
    "\n",
    "FE = FrameExtractor(yr,win_len=win_len,hop_len=hop_len)\n",
    "frame_arr = FE.extract_frames(win_type=\"rectangular\")\n",
    "y = frame_arr[30]\n",
    "\n",
    "a = librosa.lpc(y, order=3)\n",
    "print(a)\n",
    "mya = LPC(y, order=3)\n",
    "drbina,e1 = ref_derbin(auto_corr(y),order=3)\n",
    "mydrbina,e2 = derbin(auto_corr(y), p=3)\n",
    "\n",
    "print(\"librosa LPC: \\t\\t\", -1*a[1:])\n",
    "print(\"Matrix Inverse: \\t\", mya)\n",
    "print(\"Derbin's Inverse: \\t\", drbina)\n",
    "print(\"myDerbin's Inverse: \\t\", mydrbina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Filter의 Vocal Tract Response 추정해보기\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter, freqz, hamming, lfilter_zi, lfiltic\n",
    "from scipy.linalg import toeplitz, inv\n",
    "\n",
    "## GPT의 LPC \n",
    "def lpc_analysis(signal, order=10):\n",
    "    \"\"\"주어진 신호에 대한 LPC 계수를 계산합니다.\"\"\"\n",
    "    # 자기상관 함수 계산\n",
    "    autocorr = np.correlate(signal, signal, mode='full')\n",
    "    autocorr = autocorr[len(autocorr)//2:]\n",
    "\n",
    "    # 토플리츠 행렬 및 벡터 준비\n",
    "    R = toeplitz(autocorr[:order])\n",
    "    \n",
    "    r = autocorr[1:order+1]\n",
    "    \n",
    "    # LPC 계수 계산 (Levinson-Durbin 알고리즘)\n",
    "    lpc_coeffs = np.dot(inv(R), r)\n",
    "    lpc_coeffs = np.insert(lpc_coeffs, 0, 1)  # LPC 계수에 1 추가\n",
    "    return lpc_coeffs\n",
    "\n",
    "# 예제 신호 생성 (예: 사인파)\n",
    "fs = 8000  # 샘플링 주파수\n",
    "t = np.linspace(0, 1, fs)\n",
    "signal = np.sin(2 * np.pi * 440 * t) + 0.5 * np.sin(2 * np.pi * 880 * t)\n",
    "signal = frame_arr[25]\n",
    "\n",
    "# LPC 분석\n",
    "order = 12  # LPC 계수의 수\n",
    "a = LPC(signal, order=order)\n",
    "a = np.concatenate(([1],-a))\n",
    "print(a)\n",
    "w, h = freqz(b=[1], a=a)\n",
    "\n",
    "sr = 16000\n",
    "# w축을 0-0.5Fs 로 정규화\n",
    "w = w /np.pi * 0.5 * sr\n",
    "# 주파수 응답 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w, 20 * np.log10(abs(h)), label='Frequency Response')\n",
    "plt.title('Frequency Response of LPC Filter')\n",
    "plt.xlabel('Frequency [rad/sample]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "ff = np.fft.fft(signal,1024)\n",
    "ff = np.fft.fftshift(ff)\n",
    "ff = ff[len(ff)//2:]\n",
    "# ff = np.abs(ff)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w,20 * np.log10(abs(ff)))\n",
    "plt.grid()\n",
    "plt.title(\"FFT of window\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(len(ff))\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 주어진 input 신호와, 에러 신호를 그려봅시다\n",
    "## Error 신호 그리기\n",
    "\n",
    "signal = frame_arr[30]\n",
    "order = 10\n",
    "\n",
    "# LPC Analysis\n",
    "coeff = LPC(signal, order=10)\n",
    "\n",
    "# Error 전달함수의 계수\n",
    "coeff_T = np.concatenate(([1],-coeff))\n",
    "# tt = lr.lpc(signal,order=order)\n",
    "# print(tt)\n",
    "print(coeff_T)\n",
    "\n",
    "filtered = lfilter(coeff_T,[1],signal)\n",
    "\n",
    "# 입력 신호와 에러 신호(필터링된 신호) 그리기\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# 입력 신호 플롯\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot(signal, label='Input Signal')\n",
    "plt.title('Input Signal')\n",
    "plt.grid(True)\n",
    "plt.xlim(0,len(signal)-1)\n",
    "plt.legend()\n",
    "\n",
    "# 에러 신호(필터링된 신호) 플롯\n",
    "# plt.subplot(2, 1, 2)\n",
    "plt.plot(filtered, label='Filtered Signal (Error Signal)')\n",
    "plt.title('Filtered Signal (Error Signal)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlim(0,len(signal)-1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 합성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 frame에서 해야할 일\n",
    "\n",
    "\"\"\"\n",
    "LPC 계수 측정하기\n",
    "Pitch 측정하기 - voiced\n",
    "Unvoiced 판단하기\n",
    "\"\"\"\n",
    "\n",
    "signal = frame_arr[30]\n",
    "# plt.plot(signal)\n",
    "# plt.show()\n",
    "### Frame에서 진행하는 Pitch Detection\n",
    "\n",
    "## 900Hz Lowpass Filering\n",
    "cutoff_freq = 900.0\n",
    "sr = 16000\n",
    "nyquist = 0.5 * sr\n",
    "num_taps = 101 # 필터의 길이\n",
    "\n",
    "#FIR LPF\n",
    "lpf_coeff = scipy.signal.firwin(num_taps, cutoff=cutoff_freq, fs=sr, pass_zero='lowpass', window=\"hamming\")\n",
    "yr_lpf = scipy.signal.lfilter(lpf_coeff, 1.0, signal)\n",
    "\n",
    "# plt.plot(yr_lpf)\n",
    "# plt.show()\n",
    "\n",
    "# ###################### 주파수 스펙트럼 plot\n",
    "# filtered_signal = lfilter(lpf_coeff, 1.0, signal)\n",
    "\n",
    "# # 주파수 스펙트럼 계산\n",
    "# fft_original = np.fft.fft(signal)\n",
    "# fft_filtered = np.fft.fft(filtered_signal)\n",
    "# freq = np.fft.fftfreq(len(signal), 1/fs)\n",
    "\n",
    "# # 주파수 스펙트럼 시각화\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(freq, np.abs(fft_original), label='Original Signal')\n",
    "# plt.plot(freq, np.abs(fft_filtered), label='Filtered Signal', linestyle='--')\n",
    "# plt.title('Frequency Spectrum')\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.xlim(0, fs/2)  # Nyquist 주파수까지 표시\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(signal)\n",
    "# plt.plot(filtered_signal)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CL Clipping - Center clipping\n",
    "class ThresholdClipper:\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "        self.CL = self.calculate_thres()\n",
    "        self.CL_max = self.calculate_thres_max()\n",
    "        \n",
    "        \n",
    "    def calculate_thres_max(self):\n",
    "        function = np.abs(self.function)\n",
    "        CL = 0.4 * np.max(function)\n",
    "        return CL\n",
    "        \n",
    "    def calculate_thres(self):\n",
    "        function = np.abs(self.function)\n",
    "        first_max = np.max(function[0:len(function)//3]) \n",
    "        last_max = np.max(function[len(function)//3 * 2:])\n",
    "        CL = 0.68 * min(first_max,last_max)\n",
    "        return CL\n",
    "        \n",
    "    def center_clip(self,CL):\n",
    "        function = self.function\n",
    "        y = np.zeros_like(function)\n",
    "        for n in range(0,len(y)):\n",
    "            val = function[n]\n",
    "            if val >= CL:\n",
    "                y[n] = val - CL\n",
    "            elif val <= (-1*CL):\n",
    "                y[n] = val + CL\n",
    "            else:\n",
    "                y[n] = 0\n",
    "        return y\n",
    "    \n",
    "    def infinite_clip(self,CL):\n",
    "        function = self.function\n",
    "        y = np.zeros_like(function)\n",
    "        for n in range(0,len(y)):\n",
    "            val = function[n]\n",
    "            if val >= CL:\n",
    "                y[n] = 1\n",
    "            elif val <= (-1*CL):\n",
    "                y[n] = -1\n",
    "            else:\n",
    "                y[n] = 0\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 frame에서 해야할 일\n",
    "\n",
    "\"\"\"\n",
    "LPC 계수 측정하기\n",
    "Pitch 측정하기 - voiced\n",
    "Unvoiced 판단하기\n",
    "\"\"\"\n",
    "cutoff_freq = 900.0\n",
    "sr = 16000\n",
    "order = 10\n",
    "for signal in frame_arr[15:20]:\n",
    "    \n",
    "    # signal = frame_arr[30]\n",
    "    ### Frame에서 진행하는 Pitch Detection\n",
    "\n",
    "    ## 900Hz Lowpass Filering\n",
    "    #FIR LPF\n",
    "    lpf_coeff = scipy.signal.firwin(numtaps=101, cutoff=cutoff_freq, fs=sr, pass_zero='lowpass', window=\"hamming\")\n",
    "    signal_lpf = scipy.signal.lfilter(lpf_coeff, 1.0, signal)\n",
    "\n",
    "    # plt.plot(signal_lpf)\n",
    "    # plt.show()\n",
    "\n",
    "    ## Frame 에서 LPC 계수 계산하기\n",
    "    coeff = LPC(signal_lpf, order=order)\n",
    "    print(coeff)\n",
    "\n",
    "    ## Clipping 적용하기\n",
    "    Clipper = ThresholdClipper(signal_lpf)\n",
    "    signal_clipped = Clipper.center_clip(Clipper.CL)\n",
    "\n",
    "    # AC 계산하기\n",
    "    ac_arr = auto_corr(signal_clipped)\n",
    "\n",
    "    # Enery\n",
    "    energy = ac_arr[0]\n",
    "    voice_thres = energy * 0.4\n",
    "\n",
    "    # Find Peaks of AC \n",
    "    peakval = np.max(ac_arr)    \n",
    "    maxima_indices, _ = scipy.signal.find_peaks(ac_arr)\n",
    "    maxima_indices = maxima_indices[maxima_indices>50]\n",
    "    \n",
    "    if maxima_indices.size > 0:\n",
    "        maxval = np.max([ac_arr[i] for i in maxima_indices])\n",
    "        idx = np.argmax([ac_arr[i] for i in maxima_indices])\n",
    "        max_idx = maxima_indices[idx]\n",
    "    else:   \n",
    "        maxval = 0\n",
    "    flag = 1 if maxval > voice_thres else 0\n",
    "    pitch_freq = sr / max_idx if flag else 0\n",
    "    \n",
    "    print(pitch_freq)\n",
    "    plt.plot(ac_arr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch Detector 함수 만들기\n",
    "# voiced_flag : 1 if voiced, else 0\n",
    "# pitch : pitch frequency if voiced, else 0\n",
    "    \n",
    "def PitchDetector(signal, sr=16000):\n",
    "    ## Clipping 적용하기\n",
    "    Clipper = ThresholdClipper(signal)\n",
    "    signal_clipped = Clipper.center_clip(Clipper.CL)\n",
    "\n",
    "    # AC 계산하기\n",
    "    ac_arr = auto_corr(signal_clipped)\n",
    "\n",
    "    # plt.plot(ac_arr)\n",
    "    # plt.show()\n",
    "\n",
    "    # Enery\n",
    "    energy = ac_arr[0]\n",
    "    voice_thres = energy * 0.35\n",
    "\n",
    "    # Find Peaks of AC \n",
    "    peakval = np.max(ac_arr)    \n",
    "    maxima_indices, _ = scipy.signal.find_peaks(ac_arr)\n",
    "    maxima_indices = maxima_indices[maxima_indices>50]\n",
    "    \n",
    "    # print(maxima_indices)\n",
    "    if maxima_indices.size > 0:\n",
    "        maxval = np.max([ac_arr[i] for i in maxima_indices])\n",
    "        idx = np.argmax([ac_arr[i] for i in maxima_indices])\n",
    "        max_idx = maxima_indices[idx]\n",
    "        # print(maxval, voice_thres)\n",
    "        voiced_flag = 1 if maxval > voice_thres else 0\n",
    "        pitch = sr / max_idx if voiced_flag else 0\n",
    "        \n",
    "    else:\n",
    "        voiced_flag = 0\n",
    "        pitch = 0\n",
    "\n",
    "    return voiced_flag, pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 frame에서 해야할 일\n",
    "\n",
    "\"\"\"\n",
    "LPC 계수 측정하기\n",
    "Pitch 측정하기 - voiced\n",
    "Unvoiced 판단하기\n",
    "\"\"\"\n",
    "cutoff_freq = 900.0\n",
    "sr = 16000\n",
    "order = 10\n",
    "\n",
    "file_path = \"yonseicrop.wav\"\n",
    "yr,_ = lr.load(file_path,sr=sr)\n",
    "\n",
    "## LPF to yr\n",
    "lpf_coeff = scipy.signal.firwin(numtaps=101, cutoff=cutoff_freq, fs=sr, pass_zero='lowpass', window=\"hamming\")\n",
    "yr_lpf = scipy.signal.lfilter(lpf_coeff, 1.0, yr)\n",
    "\n",
    "FE = utils.FrameExtractor(yr_lpf,win_len,hop_len)\n",
    "# Pitch Detection 에서는 rectangular를 써야할 듯\n",
    "frame_arr = FE.extract_frames(win_type=\"rectangular\")\n",
    "ham_arr = FE.extract_frames(win_type=\"hamming\")\n",
    "\n",
    "i=0\n",
    "pitchlist = []\n",
    "## 20번 frame을 예로 들어봅시다\n",
    "for i, signal in enumerate(frame_arr[:]):   \n",
    "    # signal = frame_arr[30]\n",
    "    ### Frame에서 진행하는 Pitch Detection\n",
    "\n",
    "    # plt.plot(signal)\n",
    "    # plt.show()\n",
    "    # if i==5:\n",
    "    #     break\n",
    "    # i+=1\n",
    "    \n",
    "    ## Frame 에서 LPC 계수 계산하기\n",
    "    coeff = LPC(signal, order=order)\n",
    "\n",
    "    voiced_flag, pitch = PitchDetector(signal, sr)\n",
    "    if pitch: \n",
    "        print(i, \"pitch: {}\".format(pitch))\n",
    "    pitchlist.append(pitch)\n",
    "    \n",
    "    ## 20번 frame의 신호를 정확하게 reconstruct 해볼까요?\n",
    "\n",
    "# meidanfiltering to pitchlist\n",
    "pitchlist = scipy.signal.medfilt(pitchlist, kernel_size=5)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(pitchlist)\n",
    "plt.ylim(-1,200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.linspace(0,len(frame_arr),len(yr)), yr)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPC Synthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Plot LPC Spectrum\n",
    "# 신호의 스펙트럼 플롯\n",
    "def PlotLPCSpectrum(signal, sr, p=10, dftlen=2048):\n",
    "    # signal_fft = np.fft.fft(signal)\n",
    "    # signal_fft = np.fft.rfft(signal,dftlen)[1:]\n",
    "    freqs = np.linspace(0, sr/2, dftlen//2)\n",
    "    \n",
    "    # freqs = np.fft.fftfreq(len(signal_fft), 1/fs)\n",
    "    \n",
    "    coeff = LPC(signal, order=order)\n",
    "    lpc_coeff = np.concatenate(([1],-coeff))\n",
    "    w, h = scipy.signal.freqz([0.15], lpc_coeff, worN=dftlen//2, fs=fs)\n",
    "    \n",
    "    # Energy\n",
    "    signal_energy = np.sum(np.abs(np.fft.rfft(signal, dftlen//2))**2)\n",
    "    lpc_energy = np.sum(np.abs(h)**2)  # LPC 스펙트럼의 에너지 계산\n",
    "    adjust_factor = np.sqrt(signal_energy / lpc_energy)\n",
    "    \n",
    "    print(\"adj:\",adjust_factor)\n",
    "    w2, h2 = scipy.signal.freqz([adjust_factor], lpc_coeff, worN=dftlen//2, fs=sr)\n",
    "    signal_fft = np.fft.rfft(signal, 4096)\n",
    "    \n",
    "    plt.figure(figsize=(15,3))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    plt.plot(freqs, 20 * np.log10(np.abs(signal_fft[:dftlen//2])), label='Original Signal Spectrum')\n",
    "    plt.title('Signal Frequency Spectrum')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.xlim(0, sr//2)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # print(len(freqs),len(np.abs(h)))\n",
    "    # LPC 필터의 주파수 응답 플롯\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    plt.plot(freqs, 20 * np.log10(np.abs(h2)), label='LPC Filter Frequency Response')\n",
    "    plt.title('LPC Filter Frequency Response')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Gain (dB)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Plot LPC\n",
    "signal = frame_arr[5]\n",
    "PlotLPCSpectrum(signal, sr=sr, p=order)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reconstruction 20번 frame\n",
    "## 각 frame에서 해야할 일\n",
    "\n",
    "\"\"\"\n",
    "LPC 계수 측정하기\n",
    "Pitch 측정하기 - voiced\n",
    "Unvoiced 판단하기\n",
    "\"\"\"\n",
    "cutoff_freq = 900.0\n",
    "sr = 16000\n",
    "order = 15\n",
    "\n",
    "file_path = \"yonseicrop.wav\"\n",
    "yr,_ = lr.load(file_path,sr=sr)\n",
    "\n",
    "## LPF to yr\n",
    "lpf_coeff = scipy.signal.firwin(numtaps=101, cutoff=cutoff_freq, fs=sr, pass_zero='lowpass', window=\"hamming\")\n",
    "yr_lpf = scipy.signal.lfilter(lpf_coeff, 1.0, yr)\n",
    "FE = utils.FrameExtractor(yr_lpf,win_len,hop_len)\n",
    "\n",
    "# Pitch Detection 에서는 rectangular를 써야할 듯\n",
    "frame_arr = FE.extract_frames(win_type=\"rectangular\")\n",
    "signal = frame_arr[77]\n",
    "\n",
    "#######################################################\n",
    "# Pitch\n",
    "voiced_flag, pitch = PitchDetector(signal, sr)\n",
    "if pitch: \n",
    "    print(i, \"pitch: {}\".format(pitch))\n",
    "    \n",
    "## Frame 에서 LPC 계수 계산하기\n",
    "## 뽑아낸 피치 : 115 을 이용해서 impulse를 구축해볼까?\n",
    "# 8ms 단위의 impulse\n",
    "# 139 샘플?\n",
    "\n",
    "coeff = LPC(signal, order=order)\n",
    "\n",
    "if pitch: \n",
    "    duration = 0.008  # impulse 간격(초), 예시로 8ms\n",
    "    samples_per_impulse = int(sr / pitch)\n",
    "    \n",
    "    # Impulse Train 초기화, 길이를 window_length로 설정\n",
    "    impulse_train = np.zeros(len(signal))\n",
    "\n",
    "    # 각 펄스 위치에 1 설정\n",
    "    for i in range(0, len(signal), samples_per_impulse):\n",
    "        if i+50 < len(signal):\n",
    "            impulse_train[i+50] = 1\n",
    "\n",
    "    plt.plot(impulse_train)\n",
    "    plt.show()\n",
    "\n",
    "    # LPC 계수 (여기서는 예시로 사용, 실제 계산 필요)\n",
    "    lpc_coeff = np.concatenate(([1],-coeff))\n",
    "\n",
    "    # LPC 필터를 사용한 신호 합성\n",
    "    synthesized_signal = scipy.signal.lfilter([1.0], lpc_coeff, impulse_train)\n",
    "\n",
    "    # 결과 확인\n",
    "    plt.plot(synthesized_signal)\n",
    "    plt.title(\"Synthesized Signal with LPC\")\n",
    "    plt.show()\n",
    "\n",
    "    print(coeff)\n",
    "    # filtered = lfilter(coeff,[1],signal)\n",
    "\n",
    "plt.plot(signal)\n",
    "plt.title(\"Frame\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of Frame Synthesis\n",
    "\"\"\"\n",
    "\n",
    "## input 으로 frame을 받아, 해당 frame을 반환해보자\n",
    "def Synthesis(signal, sr, p=10, plotopt = False):\n",
    "    #######################################################\n",
    "    window = lr.filters.get_window(\"hann\",Nx=len(signal))\n",
    "    rectsignal = signal\n",
    "    signal = signal * window\n",
    "    \n",
    "    coeff = LPC(signal, order=p)\n",
    "    lpc_coeff = np.concatenate(([1],-coeff))\n",
    "    \n",
    "    # Pitch Detection\n",
    "    voiced_flag, pitch = PitchDetector(rectsignal, sr)\n",
    "    # print(\"signal is {}\".format(voiced_flag))\n",
    "    \n",
    "    if voiced_flag: \n",
    "        # print(\"pitch: {:.2f}Hz\".format(pitch))\n",
    "        \n",
    "        duration = 0.008  # impulse 간격(초), 예시로 8ms\n",
    "        samples_per_impulse = int(sr / pitch)\n",
    "        \n",
    "        # Impulse Train 초기화, 길이를 window_length로 설정\n",
    "        impulse_train = np.zeros(len(signal))\n",
    "\n",
    "        # 각 펄스 위치에 1 설정\n",
    "        n = 200\n",
    "        for i in range(0, len(signal), samples_per_impulse):\n",
    "            if i+n < len(signal):\n",
    "                impulse_train[i+n] = 1\n",
    "\n",
    "        # plt.plot(impulse_train)\n",
    "        # plt.show()\n",
    "\n",
    "        # LPC 필터를 사용한 신호 합성\n",
    "        synthesized_signal = scipy.signal.lfilter([1.0], lpc_coeff, impulse_train)\n",
    "\n",
    "    else : # Unvoiced\n",
    "        sig_std = np.std(signal)\n",
    "        excitation = np.random.normal(loc=0.0, scale = sig_std, size = signal.shape)\n",
    "        \n",
    "        F_excitation = np.fft.fft(excitation, len(signal))\n",
    "        w, h = scipy.signal.freqz([1],lpc_coeff,worN=len(signal),whole=True, fs=sr)\n",
    "        F_result = F_excitation*h\n",
    "        synthesized_signal = np.fft.ifft(F_result, len(signal))\n",
    "        synthesized_signal = np.real(synthesized_signal)\n",
    "    \n",
    "    # print(\"sythn length:{}\".format(len(synthesized_signal)))\n",
    "    \n",
    "    if plotopt:\n",
    "        plt.figure(figsize=(15,3))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(synthesized_signal)\n",
    "        plt.title(\"Synthesized Signal with LPC\")\n",
    "\n",
    "        # print(coeff)\n",
    "        # filtered = lfilter(coeff,[1],signal)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(signal)\n",
    "        plt.title(\"Frame\")\n",
    "        plt.show()\n",
    "        \n",
    "    return synthesized_signal\n",
    "\n",
    "    # 결과 확인\n",
    "    PlotLPCSpectrum(signal, sr=sr, p=order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SYNTHESIZE\n",
    "file_path = \"sa0_new.wav\"\n",
    "file_path = \"yonseicrop.wav\"\n",
    "y,__ = lr.load(file_path,sr=sr)\n",
    "FE = utils.FrameExtractor(y,win_len,hop_len)\n",
    "frame_arr = FE.extract_frames(win_type=\"rectangular\")\n",
    "synthesized = np.zeros_like(y)\n",
    "\n",
    "for i, signal in enumerate(frame_arr[:]):\n",
    "    tempsig = np.zeros_like(y)\n",
    "    # print(\"num: {}\".format(i))\n",
    "    start = i * hop_len\n",
    "    end = start + win_len\n",
    "    tempsig[start:end]=Synthesis(signal, sr=sr,p=8,plotopt=False)\n",
    "    synthesized = synthesized + tempsig\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(synthesized)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(y)\n",
    "plt.show()\n",
    "\n",
    "# save_path = \"synthesized.wav\"\n",
    "# # print(save_path)\n",
    "# sf.write(save_path, synthesized, sr)\n",
    "\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(synthesized, rate=sr,autoplay=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(yr, rate=sr, autoplay=True)\n",
    "\n",
    "# save_path = \"synthesized.wav\"\n",
    "# # print(save_path)\n",
    "# sf.write(save_path, synthesized, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
